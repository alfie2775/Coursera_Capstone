{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "## Applied Data Science Capstone: Predicting Severity of an Accident"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The main objective of this project is to predict the severity of an accident. And why did I choose this project is: We all know that the roadways is the most used transportation method. Since the number of people using roadways increases, the no. of vehicles used increases. It is always riskier to drive on the road knowing an accident could take place at any moment and the cost of it would be our lives. Lots of people travel using roadways and there are chances of us getting hit or hit others. Many accidents take place daily and the people no. of people die daily due to road accidents are approx. 3700([source link](https://www.cdc.gov/injury/features/global-road-safety/index.html#:~:text=Each%20year%2C%201.35%20million%20people,on%20roadways%20around%20the%20world.&text=Every%20day%2C%20almost%203%2C700%20people,pedestrians%2C%20motorcyclists%2C%20and%20cyclists.)).\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   Wouldn't it be better if we can predict the possibility of an accident occuring? And if yes, could we really make something like that possible. And the answer to it is NO. We can't predict the outcome of can accident but we can predict the probability of an accident happening using the powerful machine learning concepts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source of the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data I used to build my model is [Details of Road Accidents](https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is taken from arcGIS. The data contains a csv file of 194K+ records and 31 attributes. But I used only few attribites from it which may have an importance in predicting the result and they are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    1.) SEVERITYCODE : It is a binary valued attribute where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                       2 represents Fatality\n",
    "                       1 represents Alive [ Maybe Injured]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2.) LOCATION    :  Location at which the accident took place \n",
    "    3.) WEATHER     :  Weather at the location\n",
    "    4.) ROADCOND    :  Condition of the road at the location\n",
    "    5.) SPEEDING    :  Speed of the vehicle before the accident took place\n",
    "    6.) PERSONCOUNT :  No. of persons at the accident spot\n",
    "    7.) PEDCOUNT    :  No. of pedestrians present in the accident spot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method I'm is the __Classification__. Since we want the result to be either Fatal or Not Fatal. Classification approach is the right choice when you have to identify the label of the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification there are many classifiers, but I chose __DecisionTreeClassifier__ to build my model. There are reasons for it. Since the no. of entries of the dataset I am using is greater than 194K, the KNN and SVM would be time consuming. What I mean by that is those methods require much comptational time. While on the other hand we have Decision Trees and Logistic Regression, I've tested both the models and came up with Decision Trees since it's having higher score than Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proccess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees are decision support tools which uses a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. It uses all the features to make decisions all the way to the leaf node of that tree where we can find our answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After building the model, it was poor. I didn't realise where the mistake is. After checking few times I noticed that I didn't use Normalization  for all the feautured attributes. Normalizing the dataset is always important to achieve good results. As a result, I used one of the scaling methods from sklearn.preproccessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the result section the main mistake I found is not normalizing data. But in this section I've found more mistakes which when resolved made my model very accurate. I didn't use some of the attributes which I thought they wouldn't be necessary, but at the end they made my model work great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all the work, now, my model can predict with more than 80% if the given weather, road, light conditions etc and no. of vehicle, people, pedestrians would result in an accident or not. The DecisionTree I used works perfectly fine when we have conditions like weather road light etc where the answer of these conditions would take us to the next level of tree. And DecisionTree works well with many number of records since its compulational complexity is always proportional to the conditions of the attributes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
